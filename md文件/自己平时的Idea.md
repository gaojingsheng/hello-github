# 自己平时的Idea

## 2020.7.15

可以测试一般的神经网络能否对单一或者少量的图片进行变大变小或者乘法预测。

### 对于人来说

我举得我们能分辨一个东西，最重要的就是颜色的不同，同时人眼分辨率有限。

最早的卷积神经网络LeNet5就是由卷积层、池化层连接而成不到十层的神经网络

#### 为什么我们能分辨出猫？

我们能够获得猫不同位置的色彩图案，通过他们的位置关系我们就能得出什么是猫。

所以我们能够教网络分辨眼睛，耳朵之类的东西。然后再去分辨脸，然后根据动物的定义，就能分辨什么是狗，什么是猫，甚至看到一种动物，由于之前没见过，将其预测为一种没见过的动物。

### 如何测试？

#### 从卷积层出发，对于一层卷积层，判断它能不能准确的预测加减乘除？

实际上神经网络理论上能拟合任何函数是要求满足一定的深度和足够的神经元数量才行的。

##### 异或问题

一个感知机没法通过简单的y=w*x+b来拟合异或问题，但是两层感知机就能了。

对于分类方面的异或问题，一个线性层也没法拟合异或问题，但是多个线性分类器组合后技能表示任何决策面。

<img src="https://pic3.zhimg.com/80/v2-a1bedcb249ffd17e096286ae6175b8c6_720w.jpg" alt="img" style="zoom: 67%;" />

对于两层非线性函数就能拟合脉冲函数，所以任何函数都能用激活函数和线性函数来拟合。

所以要拟合的函数，横坐标越大或者精度越大，所需要的每一层神经元数量也会更多。

**但是：**对于任何函数来说这样理想的拟合所需要神经元的数量也太多了

##### 任意布尔运算都能通过真值表穷举

同时即使含有更多的神经元都不会影响其表达，但是神经元更少可能会影响其表达。

## 2020.7.16

今天做了一个简单的测试，发现卷积网络在拟合乘法方面明显优于加法，对于一个一层的神经网络，当训练集为10个（3，64，64）的random数据时，在1000个epochs下，对于拟合y = x + 1，预测结果在b = 0.9左右，对于拟合y = 2*x，预测结果w = 2.001

**<u>加法卷积神经网络</u>**可能有效

#### 什么是加法神经网络

我们是不是可以提出一个新的加法层，该层是通过卷积的方式对不同的层做加减法，但是卷积层本身就能做加法卷积是对卷积核大小进行y = w*x + b，所以加法的意义是什么呢？那卷积本身就是最优的吗？所以我觉得单纯的做加法好像也不是很有效。同时我发现数据很容易就陷入了局部最优，影响了数据的映射。

有一天一定要认真的从到到尾推导一波数据在网络中是怎么求导的！

这些idea都太简单了，我觉得我们现在没法从卷积上面进行改进，可以考虑改进权值更新算法。梯度求导！

#### 人眼识别其实不只是位置和颜色这么简单

实际上我们并不仅仅能够从所看到的图像的颜色、位置、强度这么简单，也不仅仅是由于焦距导致我们能够判别距离和景深。实际上我们从小就学会了自然界很多的知识，比如我们指导物体会被到眼睛中间的物体给遮挡，我们有一定的想象力。

那是不是可以基于空间层面的二维物体识别，目前已经有很多工作能够将二维图像生成三维景深的场景，我们能够基于从图像中获得东西来判断距离范围内物体的成像规则。我们可以遮挡式学习，通过可联通区域进行遮挡式bounding box，能够自己想象出类似的大小。

**我现在的问题是想的太多而看的太少！**一直想的这种学习都不是具体的任务，但是可能是未来深度学习集成的发展方向，所以我们现在需要有定位出新物体的能力？对，我们的重要应该是研究域到域之间如何拟合的更好！

初始化方法

ACL loss 确实比cycle-consistency loss高！

## 2020.7.17

今天看了华为2020的CVPR做的AdderNet，其实思路并不复杂，主要就是加法能够显著降低运算功耗之类的。实际上这种idea并不难，他们也做过很多关于修改卷积方法的尝试。

然后昨天看来的Acl loss让我刚刚想了一个idea，我们的loss一般是比较最终的结果域正确的结果之间的差异，那我们可不可能不用最终的loss，实际上用一个网络用于生成loss，然后对比预测结果和groundtruth从这个网络的输出的loss。**那就回到一个问题，什么才是一个可以评价结果的网络，而且为什么从这个网络的输出能够评价原来的问题？**

## 2020.7.21

神经网络初始值是随机的，找一个方法不随机能更好！实际上我们判断一个东西神经元也不是随机的，反而在处理某一类问题的时候参数值会向一个方向转！